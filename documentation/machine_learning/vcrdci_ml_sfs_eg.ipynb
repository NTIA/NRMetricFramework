{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0J6hcuPmUen"
      },
      "outputs": [],
      "source": [
        "!pip3 install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gnNyDJvPRq3O"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import mlxtend\n",
        "from scikeras.wrappers import KerasRegressor\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
        "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NJ9y62gfmMtB"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import backend as K\n",
        "\n",
        "\n",
        "def pearson_r(y_true, y_pred):\n",
        "    x = y_true\n",
        "    y = y_pred\n",
        "    mx = K.mean(x, axis=0)\n",
        "    my = K.mean(y, axis=0)\n",
        "    xm, ym = x - mx, y - my\n",
        "    r_num = K.sum(xm * ym)\n",
        "    x_square_sum = K.sum(xm * xm)\n",
        "    y_square_sum = K.sum(ym * ym)\n",
        "    r_den = K.sqrt(x_square_sum * y_square_sum)\n",
        "    r = r_num / r_den\n",
        "    return K.mean(r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZbB1Tg5mPrw"
      },
      "outputs": [],
      "source": [
        "vcrdci_all_data = pd.read_csv(\n",
        "    \"vcrdci_123_all_data_eg_no_nans.csv\",\n",
        "    skiprows=1,\n",
        "    names=[\n",
        "        \"media\",\n",
        "        \"mos\",\n",
        "        \"raw_mos\",\n",
        "        \"EgCodecCategory\",\n",
        "        \"S-PanSpeed\",\n",
        "        \"S-Jiggle\",\n",
        "        \"S-FineDetail\",\n",
        "        \"S-WhiteLevel\",\n",
        "        \"S-BlackLevel\",\n",
        "        \"WhiteClipping\",\n",
        "        \"S-Blur\",\n",
        "        \"viqet-sharpness\",\n",
        "        \"NR-IQA-CDI mean\",\n",
        "        \"NR-IQA-CDI std\",\n",
        "        \"NR-IQA-CDI entropy\",\n",
        "        \"NR-IQA-CDI kurtosis\",\n",
        "        \"NR-IQA-CDI skewness\",\n",
        "        \"bps\",\n",
        "        \"eps\",\n",
        "        \"mean_error\",\n",
        "        \"Ifrac\",\n",
        "        \"Pfrac\",\n",
        "        \"Bfrac\",\n",
        "        \"mean_countP_countI_ratio\",\n",
        "        \"bps_pixels\",\n",
        "        \"max_relational_error\",\n",
        "        \"mean_relational_error\",\n",
        "        \"std_raw_vs_all_error\",\n",
        "        \"mean_raw_vs_all_error\",\n",
        "        \"max_relational_bits\",\n",
        "        \"mean_relational_bits\",\n",
        "        \"std_raw_vs_all_bits\",\n",
        "        \"mean_raw_vs_all_bits\",\n",
        "        \"max_relational_countP\",\n",
        "        \"mean_relational_countP\",\n",
        "        \"std_raw_vs_all_countP\",\n",
        "        \"mean_raw_vs_all_countP\",\n",
        "        \"mean_error_vs_mean_bits\",\n",
        "        \"mean_countP_vs_mean_bits\",\n",
        "        \"max_bps\",\n",
        "        \"max_to_mean_bits_per_frame\",\n",
        "    ],\n",
        ")\n",
        "vcrdci_all_data.pop(\"media\")\n",
        "vcrdci_all_data.pop(\"mos\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "A0SZTYKimS-t"
      },
      "outputs": [],
      "source": [
        "vcrdci_60 = vcrdci_all_data[vcrdci_all_data[\"raw_mos\"] >= 60]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "AsQ95BiImUot"
      },
      "outputs": [],
      "source": [
        "vcrdci_60_small = vcrdci_60.iloc[:500]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "R4bulYkwmVkW"
      },
      "outputs": [],
      "source": [
        "vcrdci_all_features = vcrdci_60_small.copy()\n",
        "vcrdci_all_labels = vcrdci_all_features.pop(\"raw_mos\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "BTFoNdcWmWx-"
      },
      "outputs": [],
      "source": [
        "categorical_features = [\"EgCodecCategory\"]\n",
        "one_hot = OneHotEncoder()\n",
        "transformer = ColumnTransformer([(\"one_hot\", one_hot, categorical_features)], remainder = \"passthrough\")\n",
        "\n",
        "transformed_features = transformer.fit_transform(vcrdci_all_features)\n",
        "vcrdci_all_features = pd.DataFrame(transformed_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "hxhYezY6mYUL"
      },
      "outputs": [],
      "source": [
        "feature_train, feature_test, label_train, label_test = train_test_split(vcrdci_all_features, vcrdci_all_labels, test_size = 0.2, random_state = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9Sojyv7HmZih"
      },
      "outputs": [],
      "source": [
        "feature_train = np.array(feature_train)\n",
        "label_train = np.array(label_train)\n",
        "feature_test = np.array(feature_test)\n",
        "label_test = np.array(label_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "J46PnjAit2xc"
      },
      "outputs": [],
      "source": [
        "def build_model_sfs(train_input):\n",
        "    model = tf.keras.Sequential(\n",
        "        [\n",
        "            tf.keras.layers.Dense(\n",
        "                500,\n",
        "                activation=\"relu\",\n",
        "                input_shape=((train_input.shape[1]),),\n",
        "                kernel_regularizer=tf.keras.regularizers.l2(0.001),\n",
        "            ),\n",
        "            tf.keras.layers.Dropout(0.2),\n",
        "            tf.keras.layers.Dense(\n",
        "                500,\n",
        "                activation=\"relu\",\n",
        "                kernel_regularizer=tf.keras.regularizers.l2(0.001),\n",
        "            ),\n",
        "            tf.keras.layers.Dropout(0.2),\n",
        "            tf.keras.layers.Dense(1),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=\"adam\",\n",
        "        loss=tf.keras.losses.MeanSquaredError(),\n",
        "        metrics=[\"mse\", pearson_r],\n",
        "    )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "XFSAPYv5uXzt"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "class PrintDotSFS(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs):\n",
        "        if epoch % 100 == 0:\n",
        "            print(\"\")\n",
        "        print(\".\", end=\"\")\n",
        "\n",
        "early_stop_sfs = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=100, restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "P4r_p_-yuhS4"
      },
      "outputs": [],
      "source": [
        "class MakeModel(object):\n",
        "    def __init__(self, X=None, y=None):\n",
        "        pass\n",
        "\n",
        "    def predict(self, X):\n",
        "        y_pred = self.model.predict(X)\n",
        "        return y_pred\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        skwrapped_model = KerasRegressor(\n",
        "            model=build_model_sfs,\n",
        "            train_input=X,\n",
        "            epochs=1000,\n",
        "            batch_size=64,\n",
        "            validation_split=0.2,\n",
        "            verbose=0,\n",
        "            callbacks=[early_stop_sfs, PrintDotSFS()],\n",
        "        )\n",
        "        self.model = skwrapped_model\n",
        "        self.model.fit(X, y)\n",
        "        return self.model\n",
        "\n",
        "\n",
        "sffs = SFS(\n",
        "    MakeModel(),\n",
        "    k_features=(1, feature_train.shape[1]),\n",
        "    forward=True,\n",
        "    floating=False,\n",
        "    clone_estimator=False,\n",
        "    cv=0,\n",
        "    n_jobs=1,\n",
        "    scoring=\"neg_mean_squared_error\",\n",
        "    verbose=0,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2xwMPRQ_ulqP"
      },
      "outputs": [],
      "source": [
        "norm_features = tf.keras.layers.Normalization()\n",
        "norm_features.adapt(vcrdci_all_features)\n",
        "norm_train = pd.DataFrame(norm_features(feature_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1dvJJrYumGC"
      },
      "outputs": [],
      "source": [
        "sffs = sffs.fit(norm_train, label_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUd7bcjIunRU"
      },
      "outputs": [],
      "source": [
        "print(\"Best accuracy score: %.2f\" % sffs.k_score_)\n",
        "print(\"Best subset (indices):\", sffs.k_feature_idx_)\n",
        "\n",
        "fig1 = plot_sfs(sffs.get_metric_dict())\n",
        "lowest_val = pd.DataFrame.from_dict(sffs.get_metric_dict())[\"avg_score\"].min()\n",
        "plt.ylim([lowest_val, 0])\n",
        "plt.title(\"Sequential Forward Selection\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOpaNXIPus8L"
      },
      "outputs": [],
      "source": [
        "feature_train_sfs = sffs.transform(feature_train)\n",
        "feature_train_sfs = np.array(feature_train_sfs)\n",
        "feature_test_sfs = sffs.transform(feature_test)\n",
        "feature_test.to_csv(\"feature_test_vcrdci123_sfs_small.csv\", index=False)\n",
        "feature_test_sfs = np.array(feature_test_sfs)\n",
        "\n",
        "norm_features_sfs = tf.keras.layers.Normalization()\n",
        "norm_features_sfs.adapt(sffs.transform(vcrdci_all_features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPwtb-Mwu0fb"
      },
      "outputs": [],
      "source": [
        "def build_model():\n",
        "    model = tf.keras.Sequential(\n",
        "        [\n",
        "            norm_features_sfs,\n",
        "            tf.keras.layers.Dense(\n",
        "                500,\n",
        "                activation=\"relu\",\n",
        "                input_shape=[len(feature_train[0])],\n",
        "                kernel_regularizer=tf.keras.regularizers.l2(0.001),\n",
        "            ),\n",
        "            tf.keras.layers.Dropout(0.2),\n",
        "            tf.keras.layers.Dense(\n",
        "                500,\n",
        "                activation=\"relu\",\n",
        "                kernel_regularizer=tf.keras.regularizers.l2(0.001),\n",
        "            ),\n",
        "            tf.keras.layers.Dropout(0.2),\n",
        "            tf.keras.layers.Dense(1),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=\"adam\",\n",
        "        loss=tf.keras.losses.MeanSquaredError(),\n",
        "        metrics=[\"mse\", pearson_r],\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "model = build_model()\n",
        "\n",
        "\n",
        "class PrintDot(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs):\n",
        "        if epoch % 100 == 0:\n",
        "            print(\"\")\n",
        "        print(\".\", end=\"\")\n",
        "\n",
        "\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\", patience=100, restore_best_weights=True\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    feature_train_sfs,\n",
        "    label_train,\n",
        "    epochs=1000,\n",
        "    batch_size=64,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stop, PrintDot()],\n",
        "    verbose=0,\n",
        ")\n",
        "\n",
        "hist = pd.DataFrame(history.history)\n",
        "hist[\"epoch\"] = history.epoch\n",
        "\n",
        "val_rmse = np.sqrt(float(hist[\"val_mse\"].min()))\n",
        "val_pearson = float(hist[\"val_pearson_r\"].min())\n",
        "print(\"\\nFinal Root Mean Square Error on validation set: {}\".format(round(val_rmse, 3)))\n",
        "print(\n",
        "    \"Final Pearson Correlation Error on validation set: {}\".format(\n",
        "        round(val_pearson, 3)\n",
        "    )\n",
        ")\n",
        "\n",
        "print(\"\\nEvaluating...\")\n",
        "scores = model.evaluate(feature_test_sfs, label_test, verbose=0)\n",
        "test_loss_mse, test_metric_mse, test_metric_pearson = scores\n",
        "\n",
        "test_loss_rmse = np.sqrt(test_loss_mse)\n",
        "\n",
        "print(\"Loss: RMSE on test set: {}\".format(round(test_loss_rmse, 3)))\n",
        "print(\"Metric: Pearson on test set: {}\".format(round(test_metric_pearson, 3)))\n",
        "\n",
        "\n",
        "def plot_history():\n",
        "    plt.figure()\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Root Mean Square Error [VMAF Score]\")\n",
        "    plt.plot(hist[\"epoch\"], np.sqrt(hist[\"mse\"]), label=\"Train Error\")\n",
        "    plt.plot(hist[\"epoch\"], np.sqrt(hist[\"val_mse\"]), label=\"Val Error\")\n",
        "    plt.legend()\n",
        "    plt.ylim([0, 100])\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_history()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3lndVvHmiMv"
      },
      "outputs": [],
      "source": [
        "model.save(\"/content/vcrdci123_small_model_test\", save_format=\"tf\")\n",
        "!zip -r vcrdci123_small_model_test.zip vcrdci123_small_model_test/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18XtRRPomj3T"
      },
      "outputs": [],
      "source": [
        "feature_test = pd.read_csv(\"feature_test_vcrdci123_small.csv\")\n",
        "feature_test = np.array(feature_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjgQ8Qu1mo99"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(feature_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEF-irk9mqCl"
      },
      "outputs": [],
      "source": [
        "with open(\"tf_predictions.txt\", \"w+\") as f:\n",
        "  f.write(str(predictions))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
